{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from tqdm import tqdm\n",
    "import pymorphy2\n",
    "import string\n",
    "import joblib\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Таблица с исходными и исправленными запросами\n",
    "\n",
    "- orig - исходный запрос\n",
    "- new - исправленный запрос\n",
    "- deleted - удаленные из исходного запроса слова\n",
    "- added - добавленные в исходный запрос слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4410, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>deleted</th>\n",
       "      <th>added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>является ли нарушением законодательства несоот...</td>\n",
       "      <td>является ли нарушением законодательства несоот...</td>\n",
       "      <td>его на и выполнение создания в пл отраженными</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>является ли несовместное проживание с детьми п...</td>\n",
       "      <td>имеет ли право требовать пенсионный фонд при н...</td>\n",
       "      <td>отказа детьми поводом с в проживание является ...</td>\n",
       "      <td>назначении фонд имеет совместном право прожива...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>является ли объектами налогообложения налогом ...</td>\n",
       "      <td>пожарная сигнализация налог на имущество в 2019</td>\n",
       "      <td>и объектами видеонаблюдения ли система являетс...</td>\n",
       "      <td>налог</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>является ли основанием для увольнения руководи...</td>\n",
       "      <td>типовая форма договора с руководителем федерал...</td>\n",
       "      <td>указанием увольнения задолженности ли автономн...</td>\n",
       "      <td>форма руководителем договора типовая</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>- ткань должна соответствовать требованиям ГОС...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ГОСТ 29298-2005 Ткани хлопчатобумажные и смеша...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    old  \\\n",
       "4412  является ли нарушением законодательства несоот...   \n",
       "4413  является ли несовместное проживание с детьми п...   \n",
       "4414  является ли объектами налогообложения налогом ...   \n",
       "4415  является ли основанием для увольнения руководи...   \n",
       "4416                                            #ERROR!   \n",
       "\n",
       "                                                    new  \\\n",
       "4412  является ли нарушением законодательства несоот...   \n",
       "4413  имеет ли право требовать пенсионный фонд при н...   \n",
       "4414    пожарная сигнализация налог на имущество в 2019   \n",
       "4415  типовая форма договора с руководителем федерал...   \n",
       "4416  - ткань должна соответствовать требованиям ГОС...   \n",
       "\n",
       "                                                deleted  \\\n",
       "4412      его на и выполнение создания в пл отраженными   \n",
       "4413  отказа детьми поводом с в проживание является ...   \n",
       "4414  и объектами видеонаблюдения ли система являетс...   \n",
       "4415  указанием увольнения задолженности ли автономн...   \n",
       "4416                                                NaN   \n",
       "\n",
       "                                                  added  \n",
       "4412                                                NaN  \n",
       "4413  назначении фонд имеет совместном право прожива...  \n",
       "4414                                              налог  \n",
       "4415               форма руководителем договора типовая  \n",
       "4416  ГОСТ 29298-2005 Ткани хлопчатобумажные и смеша...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.read_csv('queries_fixed.csv', usecols=['нулевой запрос', 'успешный запрос', 'что выкинули', 'что добавили'])\n",
    "queries_df.columns = ['old', 'new', 'deleted', 'added']\n",
    "queries_df = queries_df[(queries_df['old'] == queries_df['old']) & (queries_df['new'] == queries_df['new'])]\n",
    "print(queries_df.shape)\n",
    "queries_df['old'] = queries_df['old'].apply(lambda sent: sent.strip())\n",
    "queries_df['new'] = queries_df['new'].apply(lambda sent: sent.strip())\n",
    "queries_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cтоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_words = []\n",
    "\n",
    "exclude_lines = open(\"exclude_words.txt\", \"r\", encoding='cp866').readlines()\n",
    "for line in exclude_lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    line = line.split('=')[-1]\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    #print(line)\n",
    "    exclude_words.extend(line.split())\n",
    "\n",
    "exclude_words = list(set(exclude_words))\n",
    "exclude_words = [word.lower() for word in exclude_words]\n",
    "len(exclude_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нормализуем запросы\n",
    "\n",
    "- norm_old\n",
    "- norm_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4410/4410 [00:25<00:00, 171.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old</th>\n",
       "      <th>new</th>\n",
       "      <th>deleted</th>\n",
       "      <th>added</th>\n",
       "      <th>norm_old</th>\n",
       "      <th>norm_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Постановление Правительства РМ16.02.2008 г № 7</td>\n",
       "      <td>Постановление Правительства РМ    от 16.02.200...</td>\n",
       "      <td>РМ16.02.2008</td>\n",
       "      <td>16.02.2008 РМ от</td>\n",
       "      <td>постановление правительство рм16022008 год 7</td>\n",
       "      <td>постановление правительство рм 16022008 год 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Действующие тарифы на перевозку пассажиров, ру...</td>\n",
       "      <td>на перевозку пассажиров, ручной клади и живности</td>\n",
       "      <td>тарифы Действующие</td>\n",
       "      <td>NaN</td>\n",
       "      <td>действующий тариф перевозка пассажир ручной кл...</td>\n",
       "      <td>перевозка пассажир ручной класть живность</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>постановление  о  мерах  социальной  поддержки...</td>\n",
       "      <td>постановление  о  мерах  социальной  поддержки...</td>\n",
       "      <td>удмуртия</td>\n",
       "      <td>NaN</td>\n",
       "      <td>постановление мера социальный поддержка работн...</td>\n",
       "      <td>постановление мера социальный поддержка работн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>практические рекомендации  по организации внут...</td>\n",
       "      <td>практические рекомендации  по организации внут...</td>\n",
       "      <td>стоматология</td>\n",
       "      <td>NaN</td>\n",
       "      <td>практический рекомендация организация внутренн...</td>\n",
       "      <td>практический рекомендация организация внутренн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>РЕШЕНИЕ от 1 августа 2018 г. N 223ФЗ-556/18</td>\n",
       "      <td>N 18/44/105/918</td>\n",
       "      <td>РЕШЕНИЕ августа от 223ФЗ-556/18 2018 г. 1</td>\n",
       "      <td>18/44/105/918</td>\n",
       "      <td>решение 1 август 2018 год 223фз55618</td>\n",
       "      <td>1844105918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 old  \\\n",
       "0     Постановление Правительства РМ16.02.2008 г № 7   \n",
       "1  Действующие тарифы на перевозку пассажиров, ру...   \n",
       "2  постановление  о  мерах  социальной  поддержки...   \n",
       "3  практические рекомендации  по организации внут...   \n",
       "4        РЕШЕНИЕ от 1 августа 2018 г. N 223ФЗ-556/18   \n",
       "\n",
       "                                                 new  \\\n",
       "0  Постановление Правительства РМ    от 16.02.200...   \n",
       "1   на перевозку пассажиров, ручной клади и живности   \n",
       "2  постановление  о  мерах  социальной  поддержки...   \n",
       "3  практические рекомендации  по организации внут...   \n",
       "4                                    N 18/44/105/918   \n",
       "\n",
       "                                     deleted             added  \\\n",
       "0                               РМ16.02.2008  16.02.2008 РМ от   \n",
       "1                         тарифы Действующие               NaN   \n",
       "2                                   удмуртия               NaN   \n",
       "3                               стоматология               NaN   \n",
       "4  РЕШЕНИЕ августа от 223ФЗ-556/18 2018 г. 1     18/44/105/918   \n",
       "\n",
       "                                            norm_old  \\\n",
       "0       постановление правительство рм16022008 год 7   \n",
       "1  действующий тариф перевозка пассажир ручной кл...   \n",
       "2  постановление мера социальный поддержка работн...   \n",
       "3  практический рекомендация организация внутренн...   \n",
       "4               решение 1 август 2018 год 223фз55618   \n",
       "\n",
       "                                            norm_new  \n",
       "0      постановление правительство рм 16022008 год 7  \n",
       "1          перевозка пассажир ручной класть живность  \n",
       "2  постановление мера социальный поддержка работн...  \n",
       "3  практический рекомендация организация внутренн...  \n",
       "4                                         1844105918  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_norm_old = []\n",
    "all_norm_new = []\n",
    "\n",
    "for row in tqdm(queries_df.itertuples(), total=queries_df.shape[0]):\n",
    "    norm_old = ''\n",
    "    row_old = row.old.translate(str.maketrans('', '', string.punctuation))\n",
    "    for word in row_old.split():\n",
    "        this_normform = morph.parse(word)[0].normal_form\n",
    "        if this_normform.lower() not in exclude_words:\n",
    "            norm_old += this_normform + ' '\n",
    "    norm_old = norm_old[:-1]\n",
    "    all_norm_old.append(norm_old)\n",
    "        \n",
    "    norm_new = ''\n",
    "    row_new = row.new.translate(str.maketrans('', '', string.punctuation))\n",
    "    for word in row_new.split():\n",
    "        this_normform = morph.parse(word)[0].normal_form\n",
    "        if this_normform.lower() not in exclude_words:\n",
    "            norm_new += this_normform + ' '\n",
    "    norm_new = norm_new[:-1]\n",
    "    all_norm_new.append(norm_new)\n",
    "\n",
    "queries_df['norm_old'] = all_norm_old\n",
    "queries_df['norm_new'] = all_norm_new\n",
    "\n",
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8820,\n",
       " ['постановление правительство рм16022008 год 7',\n",
       "  'действующий тариф перевозка пассажир ручной класть живность',\n",
       "  'постановление мера социальный поддержка работник муниципальный учреждение удмуртия',\n",
       "  'практический рекомендация организация внутренний контроль качество безопасность медицинский деятельность медицинский организация стоматология',\n",
       "  'решение 1 август 2018 год 223фз55618',\n",
       "  'внесение постановление глава администрация губернатор краснодарский край 20 январь 2017 год 48 утверждение порядок сбор число раздельный твёрдый коммунальный отход краснодарский край',\n",
       "  '04052011 99фp',\n",
       "  '1151006 налоговый декларация налог прибыль 2019 место учёт учреждение оказывать социальный услуга',\n",
       "  '17 декабря№382 внесение',\n",
       "  '19032012 161523501 порядок заполнение граф 4 счетафактура'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_normforms = all_norm_old\n",
    "all_normforms.extend(all_norm_new)\n",
    "len(all_normforms), all_normforms[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8820, 9523)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(all_normforms)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9523"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector1 = word_count_vector.copy()\n",
    "for i in range(73):\n",
    "    if i == 0:\n",
    "        word_freq_array = word_count_vector1[:10000].toarray().sum(axis=0)\n",
    "    else:\n",
    "        word_freq_array = np.vstack((word_freq_array,word_count_vector1[:10000].toarray().sum(axis=0)))\n",
    "    word_count_vector1 = word_count_vector1[10000:]\n",
    "all_word_freq = word_freq_array.sum(axis=0)\n",
    "len(all_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUYElEQVR4nO3df6jd933f8eerkqMoP0yk+kp4umJSQXSTzeLEQtPmUbI4rdWmRP7HoEJqUQwaxtuSbVCkFRb6h8Ado7SG2SCSzDJNI7Q0xiLFXYTaUAbGynXsVJZlzUrkWnfSpNuULM4Kaq2+98f5uD1IR7rnytJRdD/PBxy+n/P+fj7nfj/X+HW++pzvud9UFZKkPvzUzT4ASdLkGPqS1BFDX5I6YuhLUkcMfUnqyNKbfQDzueOOO2rdunU3+zAk6Zby0ksv/UVVTV1a/4kP/XXr1jEzM3OzD0OSbilJ/nxU3eUdSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyE/8N3Lfi3W7/nBk/c3HPz3hI5Gknwye6UtSRwx9SeqIoS9JHTH0JakjY4V+kn+X5FiSV5N8Ncn7k6xMcijJG227Yqj/7iQnk5xI8sBQ/d4kR9u+J5LkRkxKkjTavKGfZA3wb4FNVXU3sATYDuwCDlfVBuBwe06SjW3/XcBW4MkkS9rLPQXsBDa0x9brOhtJ0lWNu7yzFFieZCnwAeAMsA3Y1/bvAx5s7W3A/qq6UFWngJPA5iR3ArdX1QtVVcAzQ2MkSRMwb+hX1f8G/gvwFnAW+L9V9U1gdVWdbX3OAqvakDXA6aGXmG21Na19af0ySXYmmUkyMzc3t7AZSZKuaJzlnRUMzt7XA/8A+GCSz15tyIhaXaV+ebFqb1VtqqpNU1OX3eJRknSNxlne+RRwqqrmqupvgK8D/xw415ZsaNvzrf8ssHZo/DSD5aDZ1r60LkmakHFC/y1gS5IPtKtt7geOAweBHa3PDuC51j4IbE+yLMl6Bh/YHmlLQG8n2dJe5+GhMZKkCZj3b+9U1YtJvgZ8B3gHeBnYC3wIOJDkEQZvDA+1/seSHABea/0fq6qL7eUeBZ4GlgPPt4ckaULG+oNrVfUF4AuXlC8wOOsf1X8PsGdEfQa4e4HHKEm6TvxGriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI+PcGP1nk7wy9PhRks8nWZnkUJI32nbF0JjdSU4mOZHkgaH6vUmOtn1PtNsmSpImZN7Qr6oTVXVPVd0D3Av8FfAssAs4XFUbgMPtOUk2AtuBu4CtwJNJlrSXewrYyeC+uRvafknShCx0eed+4HtV9efANmBfq+8DHmztbcD+qrpQVaeAk8DmJHcCt1fVC1VVwDNDYyRJE7DQ0N8OfLW1V1fVWYC2XdXqa4DTQ2NmW21Na19av0ySnUlmkszMzc0t8BAlSVcydugneR/wGeC/z9d1RK2uUr+8WLW3qjZV1aapqalxD1GSNI+FnOn/IvCdqjrXnp9rSza07flWnwXWDo2bBs60+vSIuiRpQhYS+r/C3y/tABwEdrT2DuC5ofr2JMuSrGfwge2RtgT0dpIt7aqdh4fGSJImYOk4nZJ8APh54F8NlR8HDiR5BHgLeAigqo4lOQC8BrwDPFZVF9uYR4GngeXA8+0hSZqQsUK/qv4K+OlLaj9gcDXPqP57gD0j6jPA3Qs/TEnS9eA3ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHRkr9JN8JMnXkrye5HiSf5ZkZZJDSd5o2xVD/XcnOZnkRJIHhur3Jjna9j3RbpsoSZqQcc/0fxf4o6r6R8BHgePALuBwVW0ADrfnJNkIbAfuArYCTyZZ0l7nKWAng/vmbmj7JUkTMm/oJ7kd+DngSwBV9ddV9UNgG7CvddsHPNja24D9VXWhqk4BJ4HNSe4Ebq+qF6qqgGeGxkiSJmCcM/2fAeaA/5bk5SRfTPJBYHVVnQVo21Wt/xrg9ND42VZb09qX1i+TZGeSmSQzc3NzC5qQJOnKxgn9pcDHgaeq6mPA/6Mt5VzBqHX6ukr98mLV3qraVFWbpqamxjhESdI4xgn9WWC2ql5sz7/G4E3gXFuyoW3PD/VfOzR+GjjT6tMj6pKkCZk39Kvq/wCnk/xsK90PvAYcBHa02g7gudY+CGxPsizJegYf2B5pS0BvJ9nSrtp5eGiMJGkClo7Z798AX0nyPuD7wK8xeMM4kOQR4C3gIYCqOpbkAIM3hneAx6rqYnudR4GngeXA8+0hSZqQsUK/ql4BNo3Ydf8V+u8B9oyozwB3L+QAJUnXj9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZKzQT/JmkqNJXkky02orkxxK8kbbrhjqvzvJySQnkjwwVL+3vc7JJE+02yZKkiZkIWf6/7Kq7qmqd++gtQs4XFUbgMPtOUk2AtuBu4CtwJNJlrQxTwE7Gdw3d0PbL0makPeyvLMN2Nfa+4AHh+r7q+pCVZ0CTgKbk9wJ3F5VL1RVAc8MjZEkTcC4oV/AN5O8lGRnq62uqrMAbbuq1dcAp4fGzrbamta+tH6ZJDuTzCSZmZubG/MQJUnzGevG6MB9VXUmySrgUJLXr9J31Dp9XaV+ebFqL7AXYNOmTSP7SJIWbqwz/ao607bngWeBzcC5tmRD255v3WeBtUPDp4EzrT49oi5JmpB5Qz/JB5N8+N028AvAq8BBYEfrtgN4rrUPAtuTLEuynsEHtkfaEtDbSba0q3YeHhojSZqAcZZ3VgPPtqsrlwK/X1V/lOTbwIEkjwBvAQ8BVNWxJAeA14B3gMeq6mJ7rUeBp4HlwPPtIUmakHlDv6q+D3x0RP0HwP1XGLMH2DOiPgPcvfDDlCRdD34jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6MHfpJliR5Ock32vOVSQ4leaNtVwz13Z3kZJITSR4Yqt+b5Gjb90S7g5YkaUIWcqb/OeD40PNdwOGq2gAcbs9JshHYDtwFbAWeTLKkjXkK2MngFoob2n5J0oSMFfpJpoFPA18cKm8D9rX2PuDBofr+qrpQVaeAk8DmdvP026vqhaoq4JmhMZKkCRj3TP93gF8H/naotrrd7Jy2XdXqa4DTQ/1mW21Na19alyRNyLyhn+SXgfNV9dKYrzlqnb6uUh/1M3cmmUkyMzc3N+aPlSTNZ5wz/fuAzyR5E9gPfDLJ7wHn2pINbXu+9Z8F1g6NnwbOtPr0iPplqmpvVW2qqk1TU1MLmI4k6WrmDf2q2l1V01W1jsEHtH9cVZ8FDgI7WrcdwHOtfRDYnmRZkvUMPrA90paA3k6ypV218/DQGEnSBCx9D2MfBw4keQR4C3gIoKqOJTkAvAa8AzxWVRfbmEeBp4HlwPPtIUmakAWFflV9C/hWa/8AuP8K/fYAe0bUZ4C7F3qQkqTrw2/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Ms6N0d+f5EiS7yY5luQ3W31lkkNJ3mjbFUNjdic5meREkgeG6vcmOdr2PdFumyhJmpBxzvQvAJ+sqo8C9wBbk2wBdgGHq2oDcLg9J8lGBvfSvQvYCjyZZEl7raeAnQzum7uh7ZckTcg4N0avqvpxe3pbexSwDdjX6vuAB1t7G7C/qi5U1SngJLA5yZ3A7VX1QlUV8MzQGEnSBIy1pp9kSZJXgPPAoap6EVhdVWcB2nZV674GOD00fLbV1rT2pfVRP29nkpkkM3NzcwuZjyTpKsYK/aq6WFX3ANMMztqvdnPzUev0dZX6qJ+3t6o2VdWmqampcQ5RkjSGBV29U1U/BL7FYC3+XFuyoW3Pt26zwNqhYdPAmVafHlGXJE3IOFfvTCX5SGsvBz4FvA4cBHa0bjuA51r7ILA9ybIk6xl8YHukLQG9nWRLu2rn4aExkqQJWDpGnzuBfe0KnJ8CDlTVN5K8ABxI8gjwFvAQQFUdS3IAeA14B3isqi6213oUeBpYDjzfHpKkCZk39Kvqz4CPjaj/ALj/CmP2AHtG1GeAq30eIEm6gfxGriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI+PcLnFtkj9JcjzJsSSfa/WVSQ4leaNtVwyN2Z3kZJITSR4Yqt+b5Gjb90S7baIkaULGOdN/B/gPVfWPgS3AY0k2AruAw1W1ATjcntP2bQfuYnAD9SfbrRYBngJ2Mrhv7oa2X5I0IfOGflWdrarvtPbbwHFgDbAN2Ne67QMebO1twP6qulBVp4CTwOYkdwK3V9ULVVXAM0NjJEkTsKA1/STrGNwv90VgdVWdhcEbA7CqdVsDnB4aNttqa1r70vqon7MzyUySmbm5uYUcoiTpKsYO/SQfAv4A+HxV/ehqXUfU6ir1y4tVe6tqU1VtmpqaGvcQJUnzGCv0k9zGIPC/UlVfb+VzbcmGtj3f6rPA2qHh08CZVp8eUZckTcg4V+8E+BJwvKp+e2jXQWBHa+8Anhuqb0+yLMl6Bh/YHmlLQG8n2dJe8+GhMZKkCVg6Rp/7gF8FjiZ5pdX+I/A4cCDJI8BbwEMAVXUsyQHgNQZX/jxWVRfbuEeBp4HlwPPtIUmakHlDv6r+J6PX4wHuv8KYPcCeEfUZ4O6FHKAk6frxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6Mc7vELyc5n+TVodrKJIeSvNG2K4b27U5yMsmJJA8M1e9NcrTte6LdMlGSNEHjnOk/DWy9pLYLOFxVG4DD7TlJNgLbgbvamCeTLGljngJ2Mrhn7oYRrylJusHmDf2q+lPgLy8pbwP2tfY+4MGh+v6qulBVp4CTwOYkdwK3V9ULVVXAM0NjJEkTcq1r+qur6ixA265q9TXA6aF+s622prUvrY+UZGeSmSQzc3Nz13iIkqRLXe8Pcket09dV6iNV1d6q2lRVm6ampq7bwUlS76419M+1JRva9nyrzwJrh/pNA2dafXpEXZI0Qdca+geBHa29A3huqL49ybIk6xl8YHukLQG9nWRLu2rn4aExkqQJWTpfhyRfBT4B3JFkFvgC8DhwIMkjwFvAQwBVdSzJAeA14B3gsaq62F7qUQZXAi0Hnm8PSdIEzRv6VfUrV9h1/xX67wH2jKjPAHcv6OgkSdeV38iVpI4Y+pLUEUNfkjpi6EtSRwx9SerIvFfvLEbrdv3hyPqbj396wkciSZPlmb4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI11+OetK/NKWpMXOM31J6sjEz/STbAV+F1gCfLGqHp/0MSyU/wKQtFhMNPSTLAH+K/DzDG6W/u0kB6vqtUkex/VypTeDK/FNQtLNNukz/c3Ayar6PkCS/cA2BvfUXfQW+iZxLXxjkXQ1kw79NcDpoeezwD+9tFOSncDO9vTHSU5c48+7A/iLaxx7S8pv9TdnOvzvTH9z7m2+8N7n/A9HFScd+hlRq8sKVXuBve/5hyUzVbXpvb7OrcQ596G3Ofc2X7hxc5701TuzwNqh59PAmQkfgyR1a9Kh/21gQ5L1Sd4HbAcOTvgYJKlbE13eqap3kvxr4H8wuGTzy1V17Ab+yPe8RHQLcs596G3Ovc0XbtCcU3XZkrokaZHyG7mS1BFDX5I6sihDP8nWJCeSnEyy62Yfz/WS5MtJzid5dai2MsmhJG+07Yqhfbvb7+BEkgduzlG/N0nWJvmTJMeTHEvyuVZftPNO8v4kR5J8t835N1t90c4ZBt/YT/Jykm+054t6vgBJ3kxyNMkrSWZa7cbOu6oW1YPBB8TfA34GeB/wXWDjzT6u6zS3nwM+Drw6VPvPwK7W3gX8VmtvbHNfBqxvv5MlN3sO1zDnO4GPt/aHgf/V5rZo583g+ywfau3bgBeBLYt5zm0e/x74feAb7fminm+by5vAHZfUbui8F+OZ/t/9qYeq+mvg3T/1cMurqj8F/vKS8jZgX2vvAx4cqu+vqgtVdQo4yeB3c0upqrNV9Z3Wfhs4zuCb3Yt23jXw4/b0tvYoFvGck0wDnwa+OFRetPOdxw2d92IM/VF/6mHNTTqWSVhdVWdhEJDAqlZfdL+HJOuAjzE4813U825LHa8A54FDVbXY5/w7wK8DfztUW8zzfVcB30zyUvvzM3CD570Yb6Iy1p966MCi+j0k+RDwB8Dnq+pHyajpDbqOqN1y866qi8A9ST4CPJvk7qt0v6XnnOSXgfNV9VKST4wzZETtlpnvJe6rqjNJVgGHkrx+lb7XZd6L8Uy/tz/1cC7JnQBte77VF83vIcltDAL/K1X19VZe9PMGqKofAt8CtrJ453wf8JkkbzJYjv1kkt9j8c7371TVmbY9DzzLYLnmhs57MYZ+b3/q4SCwo7V3AM8N1bcnWZZkPbABOHITju89yeCU/kvA8ar67aFdi3beSabaGT5JlgOfAl5nkc65qnZX1XRVrWPw/+sfV9VnWaTzfVeSDyb58Ltt4BeAV7nR877Zn17foE/Ef4nBVR7fA37jZh/PdZzXV4GzwN8weNd/BPhp4DDwRtuuHOr/G+13cAL4xZt9/Nc453/B4J+wfwa80h6/tJjnDfwT4OU251eB/9Tqi3bOQ/P4BH9/9c6ini+DKwy/2x7H3s2qGz1v/wyDJHVkMS7vSJKuwNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfn/mdOy/c1u9D4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#распределение частот слов\n",
    "_=plt.hist(list(all_word_freq),range=[0,500],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9523"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = cv.get_feature_names()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "all_normforms_transformed = cv.transform(all_normforms)\n",
    "all_normforms_tfidf = tfidf_transformer.transform(all_normforms_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9523,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8820, 9523)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_normforms_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_split = [nf.split() for nf in all_normforms]\n",
    "phrases = Phrases(sent_split, min_count=30)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(min_count=1, # Ignores all words with total absolute frequency lower than this\n",
    "                     window=2,     # The maximum distance between the current and predicted word within a sentence.\n",
    "                     size=300,     # Dimensionality of the feature vectors.\n",
    "                     sample=6e-5,  # The threshold for configuring which higher-frequency words are randomly downsampled.\n",
    "                                   # Highly influencial.\n",
    "                     alpha=0.03,   # The initial learning rate\n",
    "                     min_alpha=0.0007, \n",
    "                     negative=0) # If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown.\n",
    "                                  # If set to 0, no negative sampling is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1108976, 1983270)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(sentences, total_examples=w2v.corpus_count, # total_examples - Count of sentences\n",
    "                epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the model more memory-efficient\n",
    "w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9651"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v.wv.vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хоз', 0.20202897489070892),\n",
       " ('повышение', 0.1987200528383255),\n",
       " ('негодность', 0.19832442700862885),\n",
       " ('30092016', 0.19421477615833282),\n",
       " ('давность', 0.19405557215213776),\n",
       " ('257182', 0.19298654794692993),\n",
       " ('отличие', 0.1927756518125534),\n",
       " ('посадочный', 0.19242554903030396),\n",
       " ('u', 0.19221648573875427),\n",
       " ('дт', 0.1853032112121582)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive='кодекс')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word_set = set(w2v.wv.index2word)\n",
    "\n",
    "# for sentences\n",
    "def avg_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чем эта величина больше, тем сильнее различаются предложения\n",
    "def sentence_difference(sent1, sent2):\n",
    "    s1_afv = avg_feature_vector(sent1, model=w2v, num_features=300, index2word_set=index2word_set)\n",
    "    s2_afv = avg_feature_vector(sent2, model=w2v, num_features=300, index2word_set=index2word_set)\n",
    "    dif = spatial.distance.cosine(s1_afv, s2_afv)\n",
    "    return dif*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.910444140434265"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_difference('постановление правительство рм16.02.2008 год № 7',\n",
    "                    'постановление правительство рм16.02.2008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.814587071537971"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_difference('постановление правительство рм16.02.2008 год № 7',\n",
    "                    'постановление о мера социальный поддержка работник муниципальный учреждение удмуртия')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.923029611818492"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_difference('постановление правительство рм16.02.2008 год № 7',\n",
    "                    'действующий тариф на перевозка пассажир ручной класть и живность')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8820/8820 [01:05<00:00, 134.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31227, 31227, 31227)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = {}\n",
    "bigrams_freq = {}\n",
    "bigrams_iter = 0\n",
    "\n",
    "for sent in tqdm(all_normforms):\n",
    "    \n",
    "    sent_split = sent.split(' ')\n",
    "    #print(sent_split)\n",
    "    for j in range(len(sent_split)-1):\n",
    "        pair = set([sent_split[j], sent_split[j+1]])\n",
    "        if pair in bigrams.values():\n",
    "            key = list(bigrams.keys())[list(bigrams.values()).index(pair)]\n",
    "            bigrams_freq[key] += 1\n",
    "        else:\n",
    "            bigrams[bigrams_iter] = pair\n",
    "            bigrams_freq[bigrams_iter] = 1\n",
    "            bigrams_iter += 1\n",
    "            \n",
    "len(bigrams), len(bigrams_freq), bigrams_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'постановление', 'правительство'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# самая частая биграмма\n",
    "bigrams[list(bigrams_freq.keys())[list(bigrams_freq.values()).index(max(bigrams_freq.values()))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_freq(word, old):\n",
    "    old = old.split(' ')\n",
    "    if len(old) < 2 or word not in old:\n",
    "        return 0\n",
    "    \n",
    "    if old.index(word) == 0:\n",
    "        pairs = [set([old[0], old[1]])]\n",
    "    if old.index(word) == len(old)-1:\n",
    "        pairs = [set([old[-1], old[-2]])]\n",
    "    else:\n",
    "        pairs = [set([old[old.index(word)], old[old.index(word)+1]]),\n",
    "                 set([old[old.index(word)], old[old.index(word)-1]])]\n",
    "    \n",
    "    res = 0\n",
    "    for pair in pairs:\n",
    "        if pair in bigrams.values():\n",
    "            key = list(bigrams.keys())[list(bigrams.values()).index(pair)]\n",
    "            res += bigrams_freq[key]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8820/8820 [01:03<00:00, 139.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31227, 31227, 31227)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = {}\n",
    "trigrams_freq = {}\n",
    "trigrams_iter = 0\n",
    "\n",
    "for sent in tqdm(all_normforms):\n",
    "    \n",
    "    sent_split = sent.split(' ')\n",
    "    #print(sent_split)\n",
    "    for j in range(len(sent_split)-2):\n",
    "        pair = set([sent_split[j], sent_split[j+1], sent_split[j+2]])\n",
    "        if pair in trigrams.values():\n",
    "            key = list(trigrams.keys())[list(trigrams.values()).index(pair)]\n",
    "            trigrams_freq[key] += 1\n",
    "        else:\n",
    "            trigrams[trigrams_iter] = pair\n",
    "            trigrams_freq[trigrams_iter] = 1\n",
    "            trigrams_iter += 1\n",
    "            \n",
    "len(bigrams), len(bigrams_freq), bigrams_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'республика', 'саха', 'якутия'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# самая частая триграмма\n",
    "trigrams[list(trigrams_freq.keys())[list(trigrams_freq.values()).index(max(trigrams_freq.values()))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_freq(word, old):\n",
    "    old = old.split(' ')\n",
    "    if len(old) < 3 or word not in old:\n",
    "        return 0\n",
    "    \n",
    "    if old.index(word) == 0 or len(old)==3:\n",
    "        pairs = [set([old[0], old[1], old[2]])]\n",
    "    if old.index(word) == len(old)-1:\n",
    "        pairs = [set([old[-1], old[-2], old[-3]])]\n",
    "    if old.index(word) == 1 or len(old)==4:\n",
    "        pairs = [set([old[0], old[1], old[2]]),\n",
    "                 set([old[1], old[2], old[3]])]\n",
    "    if old.index(word) == len(old)-2 or len(old)==4:\n",
    "        pairs = [set([old[-1], old[-2], old[-3]]),\n",
    "                 set([old[-2], old[-3], old[-4]])]\n",
    "    else:\n",
    "        pairs = [set([old[old.index(word)], old[old.index(word)+1], old[old.index(word)+2]]),\n",
    "                 set([old[old.index(word)], old[old.index(word)+1], old[old.index(word)-1]]),\n",
    "                 set([old[old.index(word)], old[old.index(word)-1], old[old.index(word)-2]])]\n",
    "    \n",
    "    res = 0\n",
    "    for pair in pairs:\n",
    "        if pair in trigrams.values():\n",
    "            key = list(trigrams.keys())[list(trigrams.values()).index(pair)]\n",
    "            res += trigrams_freq[key]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочие простые признаки\n",
    "\n",
    "- type\n",
    "- source\n",
    "- territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_words = []\n",
    "\n",
    "type_lines = open(\"type_words.txt\", \"r\", encoding='cp866').readlines()\n",
    "for line in type_lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    line = line.split('=')[-1]\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    #print(line)\n",
    "    type_words.extend(line.split())\n",
    "\n",
    "type_words = list(set(type_words))\n",
    "type_words = [word.lower() for word in type_words if len(word) > 2]\n",
    "len(type_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2290"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_words = []\n",
    "\n",
    "source_lines = open(\"source_words.txt\", \"r\", encoding='cp866').readlines()\n",
    "for line in source_lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    line = line.split('=')[-1]\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    source_words.extend(line.split())\n",
    "    \n",
    "source_words = list(set(source_words))\n",
    "source_words = [word.lower() for word in source_words if len(word) > 2]\n",
    "len(source_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terr_words = []\n",
    "\n",
    "terr_lines = open(\"territory_words.txt\", \"r\", encoding='cp866').readlines()\n",
    "for line in terr_lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    line = line.split('=')[-1]\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    terr_words.extend(line.split())\n",
    "    \n",
    "terr_words = list(set(terr_words))\n",
    "terr_words = [word.lower() for word in terr_words if len(word) > 2]\n",
    "len(terr_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересечения списков слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'муниципальный'}\n"
     ]
    }
   ],
   "source": [
    "print(set.intersection(set(type_words), set(terr_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'правового', 'налоговая', 'бюллетень', 'строительству', 'уставный', 'законодательства', 'цен', 'журнал', 'практическая', 'республиканский', 'работ', 'бухгалтерские', 'дорожная', 'конституционный', 'российского', 'судебный', 'законодательный', 'нормативные', 'строительстве', 'правовой', 'безопасности', 'федеральный', 'охране', 'материалы', 'труда', 'государственный', 'материалов'}\n"
     ]
    }
   ],
   "source": [
    "print(set.intersection(set(source_words), set(type_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'автономная', 'тыва', 'ненецкий', 'ставропольский', 'спб', 'корякский', 'осетияалания', 'пермский', 'российская', 'курская', 'московский', 'эвенкийский', 'северная', 'московская', 'адыгея', 'бурятия', 'край', 'центральный', 'еврейская', 'таймырский', 'агинский', 'комипермяцкий', 'чеченская', 'устьордынский', 'якутия', 'хабаровский', 'новая', 'ингушетия', 'сахалинская', 'башкортостан', 'саха', 'камчатский', 'область', 'краснодарский', 'республика', 'дагестан', 'коми', 'мордовия', 'бурятский', 'округ', 'красноярский', 'татарстан', 'федерация', 'магаданская', 'приморский', 'калмыкия', 'хакасия', 'чукотский', 'карелия', 'алтай', 'кировский', 'алтайский', 'марий', 'автономный'}\n"
     ]
    }
   ],
   "source": [
    "print(set.intersection(set(source_words), set(terr_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_speech(word):\n",
    "    p = morph.parse(word)[0]\n",
    "    pos = p.tag.POS\n",
    "    \n",
    "    res = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    if pos == 'NOUN':\n",
    "        res = [1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    if pos == 'ADJF' or pos == 'ADJS':\n",
    "        res = [0,1,0,0,0,0,0,0,0,0,0,0]\n",
    "    if pos == 'COMP':\n",
    "        res = [0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "    if pos == 'VERB':\n",
    "        res = [0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "    if pos == 'INFN':\n",
    "        res = [0,0,0,0,1,0,0,0,0,0,0,0]\n",
    "    if pos == 'PRTF' or pos == 'PRTS':\n",
    "        res = [0,0,0,0,0,1,0,0,0,0,0,0]\n",
    "    if pos == 'GRND':\n",
    "        res = [0,0,0,0,0,0,1,0,0,0,0,0]\n",
    "    if pos == 'NUMR':\n",
    "        res = [0,0,0,0,0,0,0,1,0,0,0,0]\n",
    "    if pos == 'ADVB':\n",
    "        res = [0,0,0,0,0,0,0,0,1,0,0,0]\n",
    "    if pos == 'NPRO':\n",
    "        res = [0,0,0,0,0,0,0,0,0,1,0,0]\n",
    "    if pos == 'PRED':\n",
    "        res = [0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "    if pos == 'PREP' or pos == 'CONJ' or pos == 'PRCL' or pos == 'INTJ':\n",
    "        res = [0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Частота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9607"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = {}\n",
    "\n",
    "for sent in all_normforms:\n",
    "    sent_split = sent.split(' ')\n",
    "    for word in sent_split:\n",
    "        if word in word_freq.keys():\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "            \n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "'постановление' in feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9523"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4410/4410 [06:07<00:00, 12.00it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 13 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         result = _convert_object_array(\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    581\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 12 columns passed, passed data had 13 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-79ea22c787d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mword_features_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m word_features_df = pd.DataFrame(word_features_table, index=row_names_list,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                 columns=['tfidf', 'idf', 'w2v_imp', 'type', 'source', 'terr',\n\u001b[0;32m     56\u001b[0m                                         'digit', 'letter', 'no_sym', 'sent_len', 'freq', 'bigram_freq']\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 12 columns passed, passed data had 13 columns"
     ]
    }
   ],
   "source": [
    "word_features_table = []\n",
    "part_of_speech_col = []\n",
    "row_names_list = []\n",
    "Y = []\n",
    "\n",
    "for it, q_row in tqdm(queries_df.iterrows(), total=queries_df.shape[0]):\n",
    "    old = q_row.old\n",
    "    new = q_row.new\n",
    "    deleted = [word for word in old.split() if word not in new.split()]\n",
    "    \n",
    "    tfidf_row = pd.DataFrame(all_normforms_tfidf[it].T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "    #print(tfidf_row)\n",
    "    for word in old.split():\n",
    "        row_names_list.append(word+'_'+str(it)+'_'+old) # row name\n",
    "            \n",
    "        Y.append(1 if word in deleted else 0) # Y\n",
    "            \n",
    "        features_row = []\n",
    "        \n",
    "        try:\n",
    "            features_row.append(tfidf_row.loc[word.lower()].tolist()[0]) # tfidf\n",
    "        except:\n",
    "            features_row.append(0)\n",
    "            \n",
    "        try:\n",
    "            features_row.append(idf_df.loc[word.lower()].tolist()[0]) # idf\n",
    "        except:\n",
    "            features_row.append(0)\n",
    "            \n",
    "        features_row.append(sentence_difference(old, old.replace(word, '').replace('  ', ' '))) # w2v_imp\n",
    "            \n",
    "        features_row.append(word.lower() in type_words) # type\n",
    "        features_row.append(word.lower() in source_words) # source\n",
    "        features_row.append(word.lower() in terr_words) # territory\n",
    "            \n",
    "        features_row.append(str(word).lower().isdigit()) # only digits\n",
    "        features_row.append(str(word).lower().isalpha()) # only letters\n",
    "        features_row.append(str(word).lower().isalnum()) # only letters and digits (no symbols)\n",
    "        \n",
    "        features_row.append(len(old.split())) # N of words in sentence\n",
    "        \n",
    "        if word in word_freq.keys():\n",
    "            features_row.append(word_freq[word]) # word freq\n",
    "        else:\n",
    "            features_row.append(0)\n",
    "           \n",
    "        features_row.append(bigram_freq(word, old))  # bigram freq\n",
    "        features_row.append(bigram_freq(word, old))  # trigram freq\n",
    "            \n",
    "        part_of_speech_col.append(part_of_speech(word)) # part of speech (12 columns)\n",
    "        \n",
    "        word_features_table.append(features_row)\n",
    "    \n",
    "word_features_df = pd.DataFrame(word_features_table, index=row_names_list,\n",
    "                                columns=['tfidf', 'idf', 'w2v_imp', 'type', 'source', 'terr',\n",
    "                                        'digit', 'letter', 'no_sym', 'sent_len', 'freq', 'bigram_freq']\n",
    "                               ).fillna(0)\n",
    "part_of_speech_df = pd.DataFrame(part_of_speech_col, index=row_names_list,\n",
    "                    columns=['NOUN','ADJ','COMP','VERB','INFN','PRT','GRND','NUMR','ADVB','NPRO','PRED', 'OTHER_POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "word_features_df = pd.DataFrame(word_features_table, index=row_names_list,\n",
    "                                columns=['tfidf', 'idf', 'w2v_imp', 'type', 'source', 'terr',\n",
    "                                        'digit', 'letter', 'no_sym', 'sent_len', 'freq', 'bigram_freq','trigram_freq']\n",
    "                               ).fillna(0)\n",
    "part_of_speech_df = pd.DataFrame(part_of_speech_col, index=row_names_list,\n",
    "                    columns=['NOUN','ADJ','COMP','VERB','INFN','PRT','GRND','NUMR','ADVB','NPRO','PRED', 'OTHER_POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57053, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "      <th>idf</th>\n",
       "      <th>w2v_imp</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>terr</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>no_sym</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>...</th>\n",
       "      <th>COMP</th>\n",
       "      <th>VERB</th>\n",
       "      <th>INFN</th>\n",
       "      <th>PRT</th>\n",
       "      <th>GRND</th>\n",
       "      <th>NUMR</th>\n",
       "      <th>ADVB</th>\n",
       "      <th>NPRO</th>\n",
       "      <th>PRED</th>\n",
       "      <th>OTHER_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Постановление_0_Постановление Правительства РМ16.02.2008 г № 7</th>\n",
       "      <td>0.303353</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Правительства_0_Постановление Правительства РМ16.02.2008 г № 7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>РМ16.02.2008_0_Постановление Правительства РМ16.02.2008 г № 7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>г_0_Постановление Правительства РМ16.02.2008 г № 7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>№_0_Постановление Правительства РМ16.02.2008 г № 7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       tfidf  idf  w2v_imp  \\\n",
       "Постановление_0_Постановление Правительства РМ1...  0.303353    0      0.0   \n",
       "Правительства_0_Постановление Правительства РМ1...  0.000000    0      0.0   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...  0.000000    0      0.0   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7  0.000000    0      0.0   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7  0.000000    0      0.0   \n",
       "\n",
       "                                                     type  source   terr  \\\n",
       "Постановление_0_Постановление Правительства РМ1...   True   False  False   \n",
       "Правительства_0_Постановление Правительства РМ1...  False    True  False   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...  False   False  False   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7  False   False  False   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7  False   False  False   \n",
       "\n",
       "                                                    digit  letter  no_sym  \\\n",
       "Постановление_0_Постановление Правительства РМ1...  False    True    True   \n",
       "Правительства_0_Постановление Правительства РМ1...  False    True    True   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...  False   False   False   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7  False    True    True   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7  False   False   False   \n",
       "\n",
       "                                                    sent_len  ...  COMP  VERB  \\\n",
       "Постановление_0_Постановление Правительства РМ1...         6  ...     0     0   \n",
       "Правительства_0_Постановление Правительства РМ1...         6  ...     0     0   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...         6  ...     0     0   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7         6  ...     0     0   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7         6  ...     0     0   \n",
       "\n",
       "                                                    INFN  PRT  GRND  NUMR  \\\n",
       "Постановление_0_Постановление Правительства РМ1...     0    0     0     0   \n",
       "Правительства_0_Постановление Правительства РМ1...     0    0     0     0   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...     0    0     0     0   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7     0    0     0     0   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7     0    0     0     0   \n",
       "\n",
       "                                                    ADVB  NPRO  PRED  \\\n",
       "Постановление_0_Постановление Правительства РМ1...     0     0     0   \n",
       "Правительства_0_Постановление Правительства РМ1...     0     0     0   \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...     0     0     0   \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7     0     0     0   \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7     0     0     0   \n",
       "\n",
       "                                                    OTHER_POS  \n",
       "Постановление_0_Постановление Правительства РМ1...          0  \n",
       "Правительства_0_Постановление Правительства РМ1...          0  \n",
       "РМ16.02.2008_0_Постановление Правительства РМ16...          0  \n",
       "г_0_Постановление Правительства РМ16.02.2008 г № 7          0  \n",
       "№_0_Постановление Правительства РМ16.02.2008 г № 7          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features_df = pd.concat([word_features_df, part_of_speech_df], axis=1)\n",
    "\n",
    "print(word_features_df.shape)\n",
    "word_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51347, 25), (5706, 25), 51347, 5706)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(word_features_df, Y, test_size=0.1, random_state=15)\n",
    "\n",
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1779, 1029],\n",
       "       [1203, 1695]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраним веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model\\\\savedweights_05.08.2020.joblib.pkl']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, 'model\\savedweights_05.08.2020.joblib.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(word_features_df)\n",
    "y_pred_proba = y_pred_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_proba = {}\n",
    "for j, query in enumerate(word_features_df.index):\n",
    "    splitted = query.split('_')\n",
    "    word = splitted[0]\n",
    "    N = splitted[1]\n",
    "    sent = ''\n",
    "    for part in splitted[2:]:\n",
    "        sent += part\n",
    "        \n",
    "    proba = y_pred_proba[j]\n",
    "    try:\n",
    "        N = int(N)\n",
    "        if N not in result_dict_proba.keys():\n",
    "            result_dict_proba[N] = {'query':sent, 'words':{word:proba}}\n",
    "        else:\n",
    "            result_dict_proba[N]['words'].update({word:proba})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output probabilities file\n",
    "\n",
    "#with open('result.txt', 'w', encoding='cp866') as file:\n",
    "#     file.write(str(result_dict_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice-looking output probabilities file\n",
    "\n",
    "res_txt = ''\n",
    "for N in result_dict_proba.keys():\n",
    "    dict_= result_dict_proba[N]\n",
    "    res_txt += dict_['query'] + '\\n\\n'\n",
    "    \n",
    "    ordered_by_prob = sorted(dict_['words'], key=lambda x:dict_['words'][x], reverse=True)\n",
    "    #print(ordered_by_prob)\n",
    "    for key in ordered_by_prob:\n",
    "        res_txt += '\\t'+\"{:.3f}\".format(dict_['words'][key])+' - '+ str(key) + '\\n'\n",
    "    res_txt += '\\n'\n",
    "    \n",
    "with open('pretty_result2.txt', 'w') as file:\n",
    "     file.write(res_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92140, 2)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2020_07.txt', sep=';0', header=None).dropna()\n",
    "data.columns = ['user', 'query']\n",
    "data['query'] = data['query'].apply(lambda x: x.replace('\\t', '').strip())\n",
    "data = data[0:92140]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilvov@vodchits.ru</td>\n",
       "      <td>реального руководителя должника и бенефициара ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ilvov@vodchits.ru</td>\n",
       "      <td>реального руководителя должника и бенефициара ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ilvov@vodchits.ru</td>\n",
       "      <td>фактического бенефициара  Вышегородцева П.Д. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victoria.Noskova1@pepsico.com</td>\n",
       "      <td>вправе ли суд назначить экспертизу в результат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiseleva@adk22.ru</td>\n",
       "      <td>| сырьевые товары по кодам ntd-l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user  \\\n",
       "0              ilvov@vodchits.ru   \n",
       "1              ilvov@vodchits.ru   \n",
       "2              ilvov@vodchits.ru   \n",
       "3  Victoria.Noskova1@pepsico.com   \n",
       "4              kiseleva@adk22.ru   \n",
       "\n",
       "                                               query  \n",
       "0  реального руководителя должника и бенефициара ...  \n",
       "1  реального руководителя должника и бенефициара ...  \n",
       "2     фактического бенефициара  Вышегородцева П.Д. .  \n",
       "3  вправе ли суд назначить экспертизу в результат...  \n",
       "4                   | сырьевые товары по кодам ntd-l  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 92140/92140 [04:21<00:00, 352.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# нормализуем\n",
    "\n",
    "all_norm = []\n",
    "for row in tqdm(data.itertuples(), total=data.shape[0]):\n",
    "    norm = ''\n",
    "    row = row.query.translate(str.maketrans('', '', string.punctuation))\n",
    "    for word in row.split():\n",
    "        this_normform = morph.parse(word)[0].normal_form\n",
    "        if this_normform.lower() not in exclude_words:\n",
    "            norm += this_normform + ' '\n",
    "    norm = norm[:-1]\n",
    "    all_norm.append(norm)\n",
    "    \n",
    "data['norm'] = all_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = cv.transform(all_norm)\n",
    "all_normforms_transformed = cv.transform(all_norm)\n",
    "all_normforms_tfidf = tfidf_transformer.transform(all_normforms_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▉| 92138/92140 [05:44<00:00, 267.67it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "row index (92140) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-21c95beaa11e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtfidf_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_normforms_tfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tfidf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print(tfidf_row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Dispatch to specialized methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m_validate_indices\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mM\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'row index (%d) out of range'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: row index (92140) out of range"
     ]
    }
   ],
   "source": [
    "# final table\n",
    "\n",
    "features_table = []\n",
    "names_list = []\n",
    "\n",
    "for it, q_row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    old = q_row.query\n",
    "    \n",
    "    tfidf_row = pd.DataFrame(all_normforms_tfidf[it].T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "    #print(tfidf_row)\n",
    "    \n",
    "    for word in old.split():\n",
    "        if word.lower() in feature_names:\n",
    "            names_list.append(word+'_'+str(it)+'_'+old) # row name\n",
    "            \n",
    "            features_row = []\n",
    "            features_row.append(tfidf_row.loc[word.lower()].tolist()[0]) # tfidf\n",
    "            features_row.append(idf_df.loc[word.lower()].tolist()[0]) # idf\n",
    "            features_row.append(sentence_difference(old, old.replace(word, '').replace('  ', ' '))) # w2v_imp\n",
    "            \n",
    "            features_row.append(word.lower() in type_words) # type\n",
    "            features_row.append(word.lower() in source_words) # source\n",
    "            features_row.append(word.lower() in terr_words) # territory\n",
    "            \n",
    "            features_row.append(str(word).lower().isdigit()) # only digits\n",
    "            features_row.append(str(word).lower().isalpha()) # only letters\n",
    "            features_row.append(str(word).lower().isalnum()) # only letters and digits (no symbols)\n",
    "        \n",
    "            features_table.append(features_row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (161063, 9), indices imply (0, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1671\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1672\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                 \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (161063, 9), indices imply (0, 9)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-249-105d7726fd38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m word_features_df = pd.DataFrame(features_table, index=names_list,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 columns=['tfidf', 'idf', 'w2v_imp', 'type', 'source', 'terr',\n\u001b[0;32m      3\u001b[0m                                         'digit', 'letter', 'no_sym']\n\u001b[0;32m      4\u001b[0m                                ).fillna(0)\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_features_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    484\u001b[0m                             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                     \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1675\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (161063, 9), indices imply (0, 9)"
     ]
    }
   ],
   "source": [
    "word_features_df = pd.DataFrame(features_table, index\n",
    "                                columns=['tfidf', 'idf', 'w2v_imp', 'type', 'source', 'terr',\n",
    "                                        'digit', 'letter', 'no_sym']\n",
    "                               ).fillna(0)\n",
    "print(word_features_df.shape)\n",
    "word_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(word_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for query in X_test.index:\n",
    "    splitted = query.split('_')\n",
    "    word = splitted[0]\n",
    "    N = splitted[1]\n",
    "    sent = ''\n",
    "    for part in splitted[2:]:\n",
    "        sent += part\n",
    "        \n",
    "    N = int(N)\n",
    "    if N not in result_dict.keys():\n",
    "        result_dict[N] = {'query':sent, 'del':[word]}\n",
    "    else:\n",
    "        result_dict[N]['del'].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [[result_dict[N]['query'], result_dict[N]['del']] for N in result_dict.keys()]\n",
    "result_df = pd.DataFrame(result, columns=['Запрос','Удалено'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
